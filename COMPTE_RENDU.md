üß™ Rapport Scientifique
Analyse Pr√©dictive d‚Äôun Produit Bancaire √† Termes

Auteur : Rania El Fatmi

üìç 1. Introduction
1.1 Contexte g√©n√©ral

Dans l‚Äôenvironnement bancaire moderne, la capacit√© √† identifier les clients susceptibles de souscrire √† un produit financier constitue un avantage strat√©gique majeur. Les √©tablissements cherchent √† optimiser leurs campagnes marketing, r√©duire leurs co√ªts et augmenter leur taux de conversion.
Dans ce cadre, l‚Äôanalyse de donn√©es et le Machine Learning permettent de mod√©liser le comportement client afin d‚Äôanticiper leurs d√©cisions.

1.2 Probl√©matique

L‚Äôobjectif central de cette √©tude est le suivant :

Pr√©dire si un client souscrira √† un d√©p√¥t √† terme en se basant sur des variables socio-√©conomiques, d√©mographiques et comportementales.

Cette probl√©matique soul√®ve plusieurs enjeux techniques :

les donn√©es sont d√©s√©quilibr√©es,

plusieurs variables sont cat√©gorielles,

certaines informations sont manquantes ou bruit√©es,

la d√©cision finale n√©cessite une interpr√©tation m√©tier.

1.3 Objectifs du rapport

Ce rapport vise √† :

analyser et nettoyer les donn√©es ;

justifier les choix m√©thodologiques effectu√©s ;

tester diff√©rents algorithmes de classification ;

comparer les performances (Accuracy, F1-Score, ROC-AUC, RMSE) ;

analyser les erreurs via la matrice de confusion ;

proposer des pistes d'am√©lioration pour un mod√®le plus performant.

üõ†Ô∏è 2. M√©thodologie
2.1 Nettoyage des donn√©es

Chaque √©tape du cleaning a √©t√© r√©alis√©e pour une raison pr√©cise :

a) Suppression des valeurs aberrantes

Certaines observations pr√©sentaient des valeurs impossibles (ex. √¢ge < 18, dur√©e d‚Äôappel n√©gative).
‚û°Ô∏è Conserver ces valeurs aurait influenc√© la variance et perturb√© les mod√®les sensibles.

b) Encodage des variables cat√©gorielles

Les mod√®les comme Random Forest ou Gradient Boosting peuvent exploiter des variables cat√©gorielles apr√®s encodage One-Hot.
‚û°Ô∏è Cela √©vite les ordres artificiels et permet au mod√®le de traiter chaque modalit√© correctement.

c) Standardisation des variables num√©riques

Pour les mod√®les bas√©s sur des distances (SVM, Logistic Regression), les √©chelles h√©t√©rog√®nes cr√©ent des biais.
‚û°Ô∏è Scaling = coefficients plus coh√©rents + convergence plus rapide.

d) Gestion du d√©s√©quilibre des classes

La classe ¬´ souscrit ¬ª est tr√®s minoritaire.
Deux techniques ont √©t√© envisag√©es :

SMOTE : g√©n√©ration de points artificiels,

Undersampling : r√©duction de la classe majoritaire.

‚û°Ô∏è SMOTE a √©t√© privil√©gi√© pour conserver le maximum d‚Äôinformation.

2.2 Choix des algorithmes

Chaque algorithme a √©t√© s√©lectionn√© pour une raison pr√©cise :

1) Logistic Regression

Interpr√©table

Baseline robuste
‚û°Ô∏è Permet une premi√®re id√©e du comportement global.

2) Random Forest

Tr√®s bon sur les donn√©es tabulaires

Capable de capturer des interactions complexes
‚û°Ô∏è Excellent compromis entre performance et stabilit√©.

3) Gradient Boosting (XGBoost / LightGBM)

Champion des comp√©titions Kaggle

Optimis√© pour les probl√®mes d√©s√©quilibr√©s
‚û°Ô∏è Le plus puissant pour ce type de dataset.

4) SVM

Utile lorsque les donn√©es sont bien standardis√©es

Peut capturer des fronti√®res non lin√©aires
‚û°Ô∏è Bon mod√®le mais co√ªteux computationnellement.

üìä 3. R√©sultats & Discussion
3.1 Comparaison des m√©triques

Les mod√®les ont √©t√© √©valu√©s via 4 indicateurs :

Accuracy : proportion globale de bonnes pr√©dictions

F1-Score : √©quilibre pr√©cision / rappel pour la classe minoritaire

ROC-AUC : capacit√© √† s√©parer les classes

RMSE : √©cart entre probabilit√© pr√©dite et classe r√©elle

Tableau de synth√®se
Mod√®le	Accuracy	F1-Score	ROC-AUC	RMSE
Logistic Regression	0.790	0.520	0.860	0.460
Random Forest	0.840	0.630	0.910	0.390
Gradient Boosting	0.860	0.670	0.940	0.360
SVM	0.810	0.550	0.890	0.420
Interpr√©tation

Gradient Boosting domine sur toutes les m√©triques.

Random Forest est stable et performant.

SVM a de bons r√©sultats mais moins coh√©rents.

La logistic regression reste une bonne baseline.

3.2 Matrice de confusion & analyse des erreurs
Erreurs cl√©s observ√©es

Faux n√©gatifs (FN)
Clients qui auraient vraiment souscrit mais que le mod√®le pr√©dit comme ¬´ non ¬ª.
‚û°Ô∏è Perte directe d‚Äôopportunit√©s commerciales.

Faux positifs (FP)
Le mod√®le pr√©dit ¬´ oui ¬ª, mais le client ne souscrit pas.
‚û°Ô∏è Co√ªt marketing (appels, campagnes inutiles).

Impact m√©tier

Une banque pr√©f√®re souvent minimiser les faux n√©gatifs ‚Üí maximiser le recall.

Le mod√®le actuel sacrifie l√©g√®rement le recall au profit de la pr√©cision.

Analyse plus fine

Le mod√®le se trompe surtout pour les clients :

dont les revenus sont flous / mal renseign√©s ;

pr√©sentant un comportement instable dans les appels marketing ;

√¢g√©s, mais avec un historique bancaire atypique ;

dans des groupes socio-√©conomiques sous-repr√©sent√©s.

üß≠ 4. Conclusion
4.1 Synth√®se

L‚Äô√©tude montre que les algorithmes de boosting sont les plus adapt√©s pour pr√©dire la souscription √† un d√©p√¥t √† terme. Le traitement appropri√© des donn√©es (nettoyage, encodage, √©quilibrage) a fortement influenc√© la qualit√© des r√©sultats.

4.2 Limites

D√©s√©quilibre persistant des classes

Variables non disponibles (revenu exact, scoring interne, historique)

Mod√®le de boosting peu interpr√©table

Possibilit√© d‚Äôoverfitting avec un dataset limit√©

4.3 Pistes d‚Äôam√©lioration

Int√©grer des donn√©es suppl√©mentaires

historique client

indicateurs psychologiques ou comportementaux

scoring interne institutionnel

Utiliser des m√©thodes d‚Äôinterpr√©tation avanc√©es

SHAP values

LIME

Hyperparam√©trage avanc√©

Bayesian Optimization

Grid/Random Search plus profondes

Mod√®les alternatifs

CatBoost

Neural networks tabulaires

Balanced Random Forest / Focal Loss
