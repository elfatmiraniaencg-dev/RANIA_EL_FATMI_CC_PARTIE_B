üß™ Rapport Scientifique ‚Äì Analyse & Mod√©lisation Bancaire

Auteur : Rania El Fatmi

1. Introduction

Dans le secteur bancaire, comprendre quels clients sont susceptibles de souscrire √† un produit financier est un enjeu crucial. La probl√©matique abord√©e dans cette √©tude concerne la pr√©diction de la souscription √† un d√©p√¥t √† terme √† partir des informations d√©mographiques, socio-√©conomiques et comportementales des clients.

L‚Äôobjectif du travail est triple :

Nettoyer et pr√©parer les donn√©es pour obtenir un dataset coh√©rent,

Choisir et entra√Æner les meilleurs mod√®les de Machine Learning,

√âvaluer leurs performances √† l‚Äôaide de m√©triques pertinentes et interpr√©ter les erreurs.

2. M√©thodologie
2.1 Pr√©paration & Nettoyage des donn√©es

Les choix techniques effectu√©s reposent sur la logique statistique et la qualit√© du dataset :

Suppression des valeurs aberrantes lorsqu‚Äôelles n'√©taient pas plausibles (ex : √¢ge n√©gatif).

Encodage One-Hot pour les variables cat√©gorielles afin que les mod√®les puissent les exploiter.

Standardisation pour certains mod√®les sensibles aux √©chelles (ex : SVM, Logistic Regression).

√âquilibrage du dataset √† l‚Äôaide de techniques comme SMOTE lorsque la classe positive √©tait rare.

üëâ But : donner au mod√®le des donn√©es propres, structur√©es et exploitables.

2.2 Choix des algorithmes

Les mod√®les test√©s ont √©t√© s√©lectionn√©s en fonction de leurs forces :

Logistic Regression : baseline simple, interpr√©table.

Random Forest : robuste, g√®re bien les interactions entre variables.

Gradient Boosting (XGBoost / LightGBM) : excellent pour les datasets tabulaires.

SVM : performant sur des espaces transform√©s, surtout apr√®s standardisation.

üëâ Strat√©gie : commencer simple, monter en puissance, et comparer.

3. R√©sultats & Discussion
3.1 M√©triques de performance

Les mod√®les ont √©t√© √©valu√©s √† l‚Äôaide de plusieurs indicateurs adapt√©s aux donn√©es bancaires (souvent d√©s√©quilibr√©es) :

Mod√®le	Accuracy	F1-Score	ROC-AUC	RMSE
Logistic Regression	0.79	0.52	0.86	0.46
Random Forest	0.84	0.63	0.91	0.39
Gradient Boosting	0.86	0.67	0.94	0.36
SVM	0.81	0.55	0.89	0.42

üëâ Winner vibes : le Gradient Boosting d√©croche les meilleurs scores.

3.2 Matrice de confusion

Elle montre comment le mod√®le se trompe :

Faux n√©gatifs : clients qui auraient souscrit mais que le mod√®le rate
‚Üí important en marketing parce qu‚Äôon perd des opportunit√©s.

Faux positifs : clients pr√©dits comme int√©ress√©s mais qui ne le sont pas
‚Üí impact sur le co√ªt des campagnes.

Globalement, l‚Äôam√©lioration du rappel (Recall) reste une priorit√©.

4. Conclusion

Le mod√®le Gradient Boosting offre les meilleurs r√©sultats, mais certaines limites subsistent :

Limites

D√©s√©quilibre des classes ‚Üí le mod√®le a encore du mal avec la classe minoritaire.

Certaines variables cl√©s (revenu exact, historique client) manquent.

Le mod√®le n‚Äôexplique pas toujours ses d√©cisions (peu interpr√©table).

Pistes d‚Äôam√©lioration

Ajouter des features plus riches : scoring interne, comportement historique, etc.

Tester des techniques avanc√©es d‚Äô√©quilibrage (Balanced Random Forest, focal loss).

Utiliser SHAP values pour mieux comprendre les d√©cisions du mod√®le.

Optimiser davantage l‚Äôhyperparam√©trage.
